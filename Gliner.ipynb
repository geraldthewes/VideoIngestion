{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6148375-7d8c-4da8-8aa1-9c23a1c839c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab107795feb4b30bba3f7a17ac910c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc9b508f58641739766b1663bc096bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42207f8926ef4eec8c5d770f1c02be5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d731a051604680a1f39f5c8257a82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gliner_config.json:   0%|          | 0.00/476 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f7c1999af8495e8b4a502abe919d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/781M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f9763722364549a40247acc1c63ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/781M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662458d735e84e8db124da860a4e6841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ac1735e89f4386930b6820ae764831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f097aea900459283171e6cb0e4326e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerald/miniconda3/envs/video-ingestion/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "# Initialize GLiNER with the base model\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d27a9c-b35c-4df3-b918-aafabed30062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b816da6-bd62-4f0d-928d-722f5980d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_into_sentences(text):\n",
    "    # Regular expression pattern to match sentence-ending punctuation followed by a space or end of string\n",
    "    sentence_endings = re.compile(r'(?<=[.!?]) +|(?<=[.!?])$')\n",
    "    \n",
    "    # Split the text into sentences using the compiled pattern\n",
    "    sentences = sentence_endings.split(text)\n",
    "    \n",
    "    # Strip any leading/trailing whitespace from each sentence\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed923465-05dd-4a48-afa3-63134988b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_sentences = split_into_sentences(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c69bcb-9b4c-45c5-9dfe-aef3371aeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = read_file_to_string('/mnt/data3/AI/software/VideoRAG/Lexington/DPa2iRgzadM.raw_transcript')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8f854a-a0e4-4d96-aaa0-5837fa1c54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Person\", \"Organizations\", \"Date\", \"Positions\", \"Locations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff46dc28-c808-4ffa-a42e-a681bb74c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform entity prediction\n",
    "entities = model.batch_predict_entities(transcript_sentences, labels, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a4a160-b43a-46e8-894a-dbd2275515fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_label(data):\n",
    "    # Initialize an empty dictionary to hold the results\n",
    "    result = {}\n",
    "\n",
    "    # Iterate through each item in the list\n",
    "    for sentence in data:\n",
    "        for entry in sentence:\n",
    "            # Check if the entry is a dictionary (to skip empty lists)\n",
    "            if isinstance(entry, dict):\n",
    "                label = entry['label']\n",
    "            \n",
    "                # Create a new dictionary with only 'text' and 'score'\n",
    "                text_score_dict = {'text': entry['text'], 'score': entry['score']}\n",
    "            \n",
    "                # Add to the result dictionary under the appropriate label\n",
    "                if label not in result:\n",
    "                    result[label] = []\n",
    "                result[label].append(text_score_dict)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "542304c9-d468-469c-8614-e7ef822a02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_by_label = group_by_label(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfbe67c9-2029-4bfd-beb9-e181ac71007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_similar_texts(data):\n",
    "    # Initialize an empty dictionary to hold the results\n",
    "    result = {}\n",
    "\n",
    "    # Iterate through each label in the input data\n",
    "    for label, entries in data.items():\n",
    "        # Use a dictionary to store unique texts with their maximum scores\n",
    "        unique_entries = {}\n",
    "\n",
    "        # Process each entry in the list of entries for the current label\n",
    "        for entry in entries:\n",
    "            text = entry['text']\n",
    "            score = entry['score']\n",
    "\n",
    "            if text in ['he','she', 'I', 'me', 'her','him','they', 'we']:\n",
    "                continue\n",
    "            # If the text is already in the unique_entries, update the score if it's higher\n",
    "            if text in unique_entries:\n",
    "                unique_entries[text] = max(unique_entries[text], score)\n",
    "            else:\n",
    "                unique_entries[text] = score\n",
    "                \n",
    "        #print(unique_entries)\n",
    "        # Convert the unique_entries dictionary back to a list of dictionaries\n",
    "        result[label] = [{'text': text, 'score': score} for text, score in unique_entries.items()]   \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d22d639e-f9b3-42d8-97b0-c9659009f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_merged = merge_similar_texts(entities_by_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de901eb-2281-4eb4-a64e-7a29e2703454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:video-ingestion]",
   "language": "python",
   "name": "conda-env-video-ingestion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
